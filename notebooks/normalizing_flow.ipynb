{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real NVP (Affine coupling Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, condition_size, rotate=True):\n",
    "        super(AffineCouplingLayer, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.upper = self.input_size // 2\n",
    "        self.lower = self.input_size - self.upper\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.condition_size = condition_size\n",
    "\n",
    "        self.translation = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.upper +self.condition_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, self.lower),\n",
    "        )\n",
    "\n",
    "        self.scale = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.upper+self.condition_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, self.lower),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.rotation = torch.eye(input_size)\n",
    "\n",
    "        if rotate:\n",
    "            self.rotation = torch.linalg.qr(torch.randn(input_size, input_size))[0]\n",
    "\n",
    "\n",
    "    def get_transforms(self, X, cond):\n",
    "\n",
    "        if self.condition_size == 0:\n",
    "            b = self.translation(X)\n",
    "            a = self.scale(X)\n",
    "\n",
    "        # one condition for multiple X\n",
    "        elif len(cond.shape) == 1:\n",
    "            full_input = torch.hstack([\n",
    "                X,\n",
    "                torch.ones((X.shape[0], self.condition_size)) *cond\n",
    "                ])\n",
    "\n",
    "            b = self.translation(full_input)\n",
    "            a = self.scale(full_input)\n",
    "\n",
    "        # each X has condition\n",
    "        else:\n",
    "            b = self.translation(torch.hstack([X, cond]))\n",
    "            a = self.scale(torch.hstack([X, cond]))\n",
    "            \n",
    "        return a, b\n",
    "    \n",
    "\n",
    "    def forward(self, x, conditions):\n",
    "        x_upper = x[:, :self.upper ]\n",
    "        x_lower = x[:, self.upper: ]\n",
    "        \n",
    "        s, t = self.get_transforms(x_upper, conditions)\n",
    "\n",
    "        z_upper = x_upper\n",
    "        z_lower = torch.exp(s) * x_lower + t\n",
    "\n",
    "        z = torch.hstack([z_upper, z_lower]) @ self.rotation\n",
    "\n",
    "        return z \n",
    "    \n",
    "    def inverse(self, x, conditions):\n",
    "        backrot_X = x @ self.rotation.T\n",
    "\n",
    "        x_upper = backrot_X[:, :self.upper ]\n",
    "        x_lower = backrot_X[:, self.upper: ]\n",
    "\n",
    "        s, t = self.get_transforms(x_upper, conditions)\n",
    "\n",
    "        z_upper = x_upper\n",
    "        z_lower = (x_lower - t) * torch.exp(-s)\n",
    "\n",
    "        z = torch.hstack([z_upper, z_lower])\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, blocks, condition_size = 0, coupling_layer = \"Affine\", printing = False):\n",
    "        super(RealNVP, self).__init__()\n",
    "\n",
    "        assert(hidden_size > input_size)\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.blocks = blocks\n",
    "        self.condition_size = condition_size\n",
    "\n",
    "        if coupling_layer==\"Affine\":\n",
    "            self.coupling_blocks = torch.nn.ModuleList([AffineCouplingLayer(self.input_size,self.hidden_size, self.condition_size) for i in range(self.blocks-1)])\n",
    "            self.coupling_blocks.append(AffineCouplingLayer(self.input_size, self.hidden_size, self.condition_size, rotate=False))\n",
    "\n",
    "        if printing == True:\n",
    "            print(\"RealNVP initialization: -----------------------------------\")\n",
    "            print(f\"input_size: {input_size}\")\n",
    "            print(f\"hidden_size: {hidden_size}\")\n",
    "            print(f\"coupling blocks: {self.coupling_blocks}\")\n",
    "            print(\"------------------------------------------------------------\")\n",
    "\n",
    "        self.Qs = torch.linalg.qr(torch.randn((self.blocks-1, self.input_size, self.input_size)))[0]\n",
    "\n",
    "    def forward(self, x, conditions = None):\n",
    "        for i, coupling_layer in enumerate(self.coupling_blocks):\n",
    "            x = coupling_layer.forward(x, conditions)\n",
    "            \n",
    "        return x \n",
    "    \n",
    "    def inverse(self, x, conditions = None):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.coupling_blocks[self.blocks-1-i].inverse(x, conditions)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def sample(self, num_samples, conditions):\n",
    "        normal_samples = torch.randn((num_samples, self.input_size))\n",
    "            \n",
    "        samples = self.decode(normal_samples, conditions)\n",
    "        \n",
    "        return samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class LightningINN(L.LightningModule):\n",
    "    def __init__(self, inn: RealNVP):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inn = inn\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, conditions = batch      \n",
    "                            \n",
    "        size = x.shape[0]\n",
    "        z = x\n",
    "        log_det_jac = 0\n",
    "        for block in self.inn.coupling_blocks:\n",
    "            log_det_jac += torch.sum(block.get_transforms(z[:, :block.upper], conditions)[0])\n",
    "            z = block(z, conditions)\n",
    "            \n",
    "        loss = ( 1 / size ) * ( ( torch.sum(torch.square(z)) / 2 ) - log_det_jac )\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
